{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MRNet Ensemble of Models",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GwmbMAcAoTu",
        "colab_type": "text"
      },
      "source": [
        "**As a solution for MRNET problem, we have made up 2 approaches but both are common in the fact that they consists of 9 different models. So we need an Ensemble method to combine those 9 Models and get an actual answer for the problem !**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cP1yHy6gBlXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#imports cell \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense,Input,Flatten,GlobalAveragePooling2D,Dropout,InputLayer,GlobalAveragePooling3D,Reshape,BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import optimizers\n",
        "K.set_image_data_format(\"channels_first\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E547RnrVBtth",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fdef9dc8-8bad-45ad-d4f2-fa78b75dbc6c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScV8BNIkChLt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_validation_interrpolation_data(plane,label):\n",
        "  #feature extractor\n",
        "  base_model = VGG16(weights='imagenet',input_shape=(3,256,256),include_top=False,input_tensor=Input(shape=(3,256,256)))\n",
        "  #Global Average Pooling\n",
        "  inputs=Input(shape=(512,8,8))\n",
        "  gap=GlobalAveragePooling2D()(inputs)\n",
        "  model_gap=Model(inputs=inputs,outputs=gap)\n",
        "  valid_X = np.load('/content/gdrive/My Drive/Dataset/Transformations/interpolated24_valid_' + plane + '.npy')\n",
        "  val_X_2 = np.load('/content/gdrive/My Drive/Dataset/Transformations/mid3_valid_'+plane+'.npy') \n",
        "  valid_X=np.stack([valid_X]*3,axis=2)\n",
        "  valid_Y = np.genfromtxt('/content/gdrive/My Drive/Dataset/MRNet-v1.0/valid-' + label + '.csv',delimiter=',')[:,1]\n",
        "  new_valid_X = np.zeros(shape=(120,24,512))\n",
        "  for i in range(120):\n",
        "    first_output=base_model.predict(valid_X[i])\n",
        "    new_valid_X[i] = model_gap.predict(first_output)\n",
        "  valid_X = None\n",
        "  new_valid_X=new_valid_X.reshape(120,512,24,1)\n",
        "  return new_valid_X,val_X_2,valid_Y\n",
        "\n",
        "  \n",
        "def eval_model(label):\n",
        "  #define your models.\n",
        "  axial_model = load_model(\"/content/gdrive/My Drive/Models/PaperImplementation/axial_\"+label+\".h5\")\n",
        "  coronal_model = load_model(\"/content/gdrive/My Drive/Models/PaperImplementation/coronal_\"+label+\".h5\")\n",
        "  sagittal_model = load_model(\"/content/gdrive/My Drive/Models/PaperImplementation/sagittal_\"+label+\".h5\")\n",
        "  axial_model_TL = load_model(\"/content/gdrive/My Drive/Models/TransferLearning/axial_\"+label+\".h5\")\n",
        "  coronal_model_TL = load_model(\"/content/gdrive/My Drive/Models/TransferLearning/coronal_\"+label+\".h5\")\n",
        "  sagittal_model_TL = load_model(\"/content/gdrive/My Drive/Models/TransferLearning/sagittal_\"+label+\".h5\")\n",
        "  \n",
        "  #load and predict on data.\n",
        "  val_X,val_X_TL,val_y = load_validation_interrpolation_data('axial',label)\n",
        "  w1 = axial_model.evaluate(val_X,val_y,verbose =0)[1]\n",
        "  axial_preds = (axial_model.predict(val_X) > 0.5).astype(np.int_).ravel()\n",
        "  w2 = axial_model_TL.evaluate(val_X_TL,val_y,verbose =0)[1]\n",
        "  axial_preds_TL = (axial_model_TL.predict(val_X_TL) > 0.5).astype(np.int_).ravel()\n",
        "  \n",
        "  \n",
        "  val_X,val_X_TL,val_y = load_validation_interrpolation_data('coronal',label)\n",
        "  w3 = coronal_model.evaluate(val_X,val_y,verbose =0)[1]\n",
        "  coronal_preds = (coronal_model.predict(val_X) > 0.5).astype(np.int_).ravel()\n",
        "  w4 = coronal_model_TL.evaluate(val_X_TL,val_y,verbose =0)[1]\n",
        "  coronal_preds_TL = (coronal_model_TL.predict(val_X_TL) > 0.5).astype(np.int_).ravel()\n",
        "  \n",
        "  \n",
        "  val_X,val_X_TL,val_y = load_validation_interrpolation_data('sagittal',label)\n",
        "  w5 = sagittal_model.evaluate(val_X,val_y,verbose =0)[1]\n",
        "  sagittal_preds = (sagittal_model.predict(val_X) > 0.5).astype(np.int_).ravel()\n",
        "  w6 = sagittal_model_TL.evaluate(val_X_TL,val_y,verbose =0)[1]\n",
        "  sagittal_preds_TL = (sagittal_model_TL.predict(val_X_TL) > 0.5).astype(np.int_).ravel()\n",
        "  \n",
        "  #intialize main vector to store predicitions.\n",
        "  preds = np.arange(len(axial_preds))\n",
        "  weights = np.array([w1,w2,w3,w4,w5,w6])\n",
        "  for i in range(len(axial_preds)):\n",
        "    preds[i] = np.argmax(np.bincount(np.array([axial_preds[i],coronal_preds[i],\n",
        "                                               sagittal_preds[i],axial_preds_TL[i],\n",
        "                                               coronal_preds_TL[i],sagittal_preds_TL[i]]),weights))\n",
        "    \n",
        "  return accuracy_score(val_y,preds)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CedL3zMqA720",
        "colab_type": "text"
      },
      "source": [
        "# Ensemble Weighted Majority Voting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD7CWwY7Af4h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20800289-c9e9-495d-9210-6def7003a942"
      },
      "source": [
        "eval_model('abnormal')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8916666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKqZlRyVBZl5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57e81048-491e-4532-b3b8-9450bb98f721"
      },
      "source": [
        "eval_model('acl')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBvtmax_YFLh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "02607168-7c11-4b28-ec7a-22cec8fa4bd6"
      },
      "source": [
        "eval_model('meniscus')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7166666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwI4BsB4vABG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}